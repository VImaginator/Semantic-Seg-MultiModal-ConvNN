
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#FOR MODIFYING IMAGES AND ARRAYS\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "#KERAS IMPORTS\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ProgbarLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, Conv2DTranspose, Conv2D, core\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "#UTILITY GLOBAL VARIABLES\n",
    "input_dim = [512, 960]  \n",
    "num_class = 6\n",
    "C = 10\n",
    "index = [2380, 1020,  969,  240, 2775,    0]\n",
    "\n",
    "#HELPER FUNCTION OF SEGMENT_DATA_GENERATOR\n",
    "# comprises of path and extension of images in a directory\n",
    "class gen_args:\n",
    "    data_dir = None\n",
    "    data_ext = None\n",
    "    def __init__(self,dirr,ext):\n",
    "        self.data_dir = dirr\n",
    "        self.data_ext = ext\n",
    "        \n",
    "\n",
    "#RESIZES 3D IMAGES(image)(EX: RGB) TO DESIRED SIZE(crop_size) \n",
    "def fix_size(image, crop_size):\n",
    "    cropy, cropx = crop_size\n",
    "    height, width = image.shape[:-1]\n",
    "    \n",
    "    #adjusting height of the image \n",
    "    cy = cropy - height\n",
    "    if cy > 0:\n",
    "        if cy % 2 == 0:\n",
    "            image = np.vstack((np.zeros((cy/2,width,3)) , image , np.zeros((cy/2,width,3))))\n",
    "        else:\n",
    "            image = np.vstack((np.zeros((cy/2,width,3)) , image , np.zeros((cy/2 +1,width,3))))\n",
    "    if cy < 0:\n",
    "        if cy % 2 == 0:\n",
    "            image = np.delete(image, range(-1*cy/2), axis = 0)\n",
    "            image = np.delete(image, range(height + cy,height +  cy/2), axis = 0)\n",
    "        else:\n",
    "            image = np.delete(image, range(-1*cy/2), axis =0)\n",
    "            image = np.delete(image, range(height + cy, height + cy/2 + 1), axis=0)\n",
    "    \n",
    "    #adjusting width of the image\n",
    "    height, width = image.shape[:-1]\n",
    "    cx = cropx - width\n",
    "    if cx > 0:\n",
    "        if cx % 2 == 0:\n",
    "            image = np.hstack((np.zeros((height,cx/2,3)) , image , np.zeros((height,cx/2,3))))\n",
    "        else:\n",
    "            image = np.hstack((np.zeros((height,cx/2,3)) , image , np.zeros((height,cx/2 + 1,3))))\n",
    "    if cx < 0:\n",
    "        if cx % 2 == 0:\n",
    "            image = np.delete(image, range(-1*cx/2), axis = 1)\n",
    "            image = np.delete(image, range(width + cx,width +  cx/2), axis = 1)\n",
    "        else:\n",
    "            image = np.delete(image, range(-1*cx/2), axis =1)\n",
    "            image = np.delete(image, range(width + cx, width + cx/2 + 1), axis=1)\n",
    "    return image\n",
    "\n",
    "#====================================================data==augmentation==============================================================\n",
    "class aug_state:\n",
    "    def __init__(self,flip_axis_index=0,rotation_range=360,height_range=0.2,width_range=0.2,shear_intensity=1,color_intensity=40,zoom_range=(1.2,1.2)):\n",
    "        self.flip_axis_index=flip_axis_index\n",
    "        self.rotation_range=rotation_range\n",
    "        self.height_range=height_range\n",
    "        self.width_range=width_range\n",
    "        self.shear_intensity=shear_intensity\n",
    "        self.color_intensity=color_intensity\n",
    "        self.zoom_range=zoom_range\n",
    "\n",
    "\n",
    "def data_augmentor(x,state,row_axis=0,col_axis=1,channel_axis=-1,\n",
    "    bool_flip_axis=True,\n",
    "    bool_random_rotation=True,\n",
    "    bool_random_shift=True,\n",
    "    bool_random_shear=True,\n",
    "    bool_random_channel_shift=True,\n",
    "    bool_random_zoom=True):\n",
    "    if bool_flip_axis:\n",
    "        flip_axis(x, state.flip_axis_index)\n",
    "\n",
    "    if bool_random_rotation:\n",
    "        random_rotation(x, state.rotation_range, row_axis, col_axis, channel_axis)\n",
    "\n",
    "    if bool_random_shift:\n",
    "        random_shift(x, state.width_range, state.height_range, row_axis, col_axis, channel_axis)\n",
    "\n",
    "    if bool_random_shear:\n",
    "        random_shear(x, state.shear_intensity, row_axis, col_axis, channel_axis)\n",
    "\n",
    "    if bool_random_channel_shift:\n",
    "        random_channel_shift(x, state.color_intensity, channel_axis)\n",
    "\n",
    "    if bool_random_zoom:\n",
    "        random_zoom(x, state.zoom_range, row_axis, col_axis, channel_axis)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "#=====================================================================================================================\n",
    "#DATAGENERATOR FOR MULTIMODAL SEMANTIC SEGMENTATION\n",
    "def datagen(state_aug,file_path, input_args, label_args, batch_size, input_size):\n",
    "    # Create MEMORY enough for one batch of input(s) + augmented input(s) & labels + augmented labels\n",
    "    data = np.zeros((batch_size*2,input_size[0],input_size[1],3))\n",
    "    labels = np.zeros((batch_size*2,input_size[0],input_size[1],3))\n",
    "    # Read the file names\n",
    "    files = open(file_path)\n",
    "    names = files.readlines()\n",
    "    files.close()\n",
    "    # Enter the indefinite loop of generator\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            index_of_random_sample = np.random.choice(len(names))\n",
    "            np.random.seed(i)\n",
    "            data[i] = fix_size(cv2.imread(input_args.data_dir+names[index_of_random_sample].strip('\\n')+input_args.data_ext), input_size)\n",
    "            data[batch_size+i] = data_augmentor(data[i],state_aug)\n",
    "            np.random.seed(i)\n",
    "            labels[i] = fix_size(cv2.imread(label_args.data_dir+names[index_of_random_sample].strip('\\n')+label_args.data_ext), input_size)\n",
    "            labels[batch_size+i] = data_augmentor(labels[i], state_aug, bool_random_channel_shift= False)\n",
    "        yield [data],[labels]\n",
    "\n",
    "#ARGUMENTS FOR DATA_GENERATOR\n",
    "Train_DEPTH_args = gen_args ('/home/captain_jack/Downloads/freiburg_forest_annotated/train/depth_color/','.png')\n",
    "Train_NIR_args = gen_args ('/home/captain_jack/Downloads/freiburg_forest_annotated/train/nir_color/','.png')\n",
    "Valid_DEPTH_args = gen_args ('/home/captain_jack/Downloads/freiburg_forest_annotated/valid/depth_color/','.png')\n",
    "Valid_NIR_args = gen_args ('/home/captain_jack/Downloads/freiburg_forest_annotated/valid/nir_color/','.png')\n",
    "\n",
    "state_aug = aug_state() \n",
    "\n",
    "train_generator = datagen(state_aug,\n",
    "    file_path = '/home/captain_jack/Downloads/freiburg_forest_annotated/Otherformats/train.txt',\n",
    "    input_args = Train_DEPTH_args,\n",
    "    label_args = Train_NIR_args,\n",
    "    batch_size= 8,\n",
    "    input_size=input_dim)\n",
    "\n",
    "\n",
    "valid_generator = datagen(state_aug,\n",
    "    file_path = '/home//captain_jack/Downloads/freiburg_forest_annotated/Otherformats/valid.txt',\n",
    "    input_args = Valid_DEPTH_args,\n",
    "    label_args = Valid_NIR_args,\n",
    "    batch_size= 8,\n",
    "    input_size=input_dim)\n",
    "\n",
    "#================================================MODEL_ARCHITECTURE============================================================\n",
    "\n",
    "# RGB MODALITY BRANCH OF CNN\n",
    "inputs_rgb = Input(shape=(input_dim[0],input_dim[1],3))\n",
    "vgg_model_rgb = VGG16(weights='imagenet', include_top= False)\n",
    "conv_model_rgb = vgg_model_rgb(inputs_rgb)\n",
    "conv_model_rgb = Conv2D(1024, (3,3), strides=(1, 1), padding = 'same', activation='relu',data_format=\"channels_last\") (conv_model_rgb)\n",
    "conv_model_rgb = Conv2D(1024, (3,3), strides=(1, 1), padding = 'same', activation='relu',data_format=\"channels_last\") (conv_model_rgb)\n",
    "deconv_rgb_1 = Conv2DTranspose(num_class*C,(4,4), strides=(2, 2), padding='same', data_format=\"channels_last\", activation='relu',kernel_initializer='glorot_normal')(conv_model_rgb)\n",
    "#============================================================================================================\n",
    "conv_rgb_1 = Conv2D(num_class*C, (3,3), strides=(1,1), padding = 'same', activation='relu', data_format='channels_last')(deconv_rgb_1)\n",
    "dropout_rgb = core.Dropout(0.4)(conv_rgb_1)\n",
    "#===============================================================================================================\n",
    "deconv_rgb_2 = Conv2DTranspose(num_class*C,(4,4), strides=(2, 2), padding='same', data_format=\"channels_last\", activation='relu',kernel_initializer='glorot_normal')(dropout_rgb)\n",
    "conv_rgb_2 = Conv2D(num_class*C, (3,3), strides=(1,1), padding = 'same', activation='relu', data_format='channels_last')(deconv_rgb_2)\n",
    "deconv_rgb_3 = Conv2DTranspose(num_class*C,(4,4), strides=(2, 2), padding='same', data_format=\"channels_last\", activation='relu',kernel_initializer='glorot_normal')(conv_rgb_2)\n",
    "conv_rgb_3 = Conv2D(num_class*C, (3,3), strides=(1,1), padding = 'same', activation='relu', data_format='channels_last')(deconv_rgb_3)\n",
    "deconv_rgb_4 = Conv2DTranspose(num_class*C,(4,4), strides=(2, 2), padding='same', data_format=\"channels_last\", activation='relu',kernel_initializer='glorot_normal')(conv_rgb_3)\n",
    "conv_rgb_4 = Conv2D(num_class*C, (3,3), strides=(1,1), padding = 'same', activation='relu', data_format='channels_last')(deconv_rgb_4)\n",
    "deconv_rgb_5 = Conv2DTranspose(num_class*C,(4,4), strides=(2, 2), padding='same', data_format=\"channels_last\", activation='relu',kernel_initializer='glorot_normal')(conv_rgb_4)\n",
    "\n",
    "\n",
    "# DECONVOLUTION Layers\n",
    "deconv_last = Conv2DTranspose(3,\n",
    "                              (1,1),\n",
    "                              strides=(1, 1),\n",
    "                              padding='same',\n",
    "                              data_format=\"channels_last\",\n",
    "                              activation='relu',\n",
    "                              kernel_initializer='glorot_normal') (deconv_rgb_5)\n",
    "\n",
    "# MODAL [INPUTS , OUTPUTS]\n",
    "model = Model(inputs=[inputs_rgb], outputs=[deconv_last])\n",
    "print 'compiling'\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "progbar = ProgbarLogger(count_mode='steps')\n",
    "checkpoint = ModelCheckpoint(\"nir_rgb_segmentation_2.{epoch:02d}.hdf5\", monitor='val_acc', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "#early = EarlyStopping(monitor='val_acc', min_delta=0, patience=1, verbose=1, mode='auto')\n",
    "#haven't specified validation data directory yet\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,steps_per_epoch=2000,epochs=50,callbacks=[progbar,checkpoint],validation_data = valid_generator,validation_steps = 2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },